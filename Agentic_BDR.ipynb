{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4abe3285-410b-4f79-b3dc-20a1967d7ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "994532eb-1413-43cd-96e0-09e1eb9d713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install hubspot-api-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2640ccc-db51-43b2-8a76-2baf5aec611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAKE A LIST OF THE TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4045385-9f2b-430b-9385-39c804399759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/kevincorstorphine/Library/Caches/pypoetry/virtualenvs/a003-poetry-setup-nf8eJWHB-py3.11/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /Users/kevincorstorphine/Library/Caches/pypoetry/virtualenvs/a003-poetry-setup-nf8eJWHB-py3.11/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/kevincorstorphine/Library/Caches/pypoetry/virtualenvs/a003-poetry-setup-nf8eJWHB-py3.11/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/kevincorstorphine/Library/Caches/pypoetry/virtualenvs/a003-poetry-setup-nf8eJWHB-py3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/kevincorstorphine/Library/Caches/pypoetry/virtualenvs/a003-poetry-setup-nf8eJWHB-py3.11/lib/python3.11/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/kevincorstorphine/Library/Caches/pypoetry/virtualenvs/a003-poetry-setup-nf8eJWHB-py3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5436a0eb-72d9-40b3-b51c-88277c4c3b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevincorstorphine/Desktop/Agentic_Start\n",
      "Loading .env file from: /Users/kevincorstorphine/Desktop/Agentic_Start/.env\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "hubspot_api_key = os.getenv('HUBSPOT_API_KEY')\n",
    "google_place_api_key = os.environ[\"GOOGLE_PLACE_API_KEY\"]\n",
    "\n",
    "\n",
    "print(os.getcwd())\n",
    "dotenv_path = find_dotenv()\n",
    "print(f\"Loading .env file from: {dotenv_path}\")\n",
    "_ = load_dotenv(dotenv_path)\n",
    "\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "\n",
    "creativeLlmModel = OpenAI(temperature=0.9)\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llmModel = OpenAI()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3b807-8344-4e8d-bed1-527747f9e25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8e6a73e-92c6-4893-b736-bd36012cfcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GOOGLE PLACES API to find names of businesses in a certain area. Get API Keys and have Google do it.\n",
    "# Linkedin Sales Navigator to find the contact information of the people (maybe sales nav) ~$99/mo\n",
    "# Zoominfo to get their people, and then contact information.\n",
    "\n",
    "# Upload all data to Hubspot CRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aed36862-39ec-46d7-91b7-c3658dc1d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accountant\n",
    "# Law\n",
    "# Construction\n",
    "# Manufacturing\n",
    "# Property management\n",
    "# Dentists\n",
    "# Distribution\n",
    "# Industrial\n",
    "# Dental\n",
    "# Optometrist\n",
    "# Health\n",
    "# Local_government_office\n",
    "# Accounting\n",
    "# Finance\n",
    "# Veterinary_care\n",
    "# School\n",
    "# Museum\n",
    "# Car_rental\n",
    "# Insurance_agency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a037ce8-731b-4e9d-88a8-a6b5eda97df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the town name:  los alamos, ca\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for businesses in los alamos, ca...\n",
      "Searching in area centered at 34.7044264,-120.31821140000001\n",
      "Searching in area centered at 34.7044264,-120.2982114\n",
      "Searching in area centered at 34.7044264,-120.2782114\n",
      "Searching in area centered at 34.7044264,-120.25821140000001\n",
      "Searching in area centered at 34.7044264,-120.2382114\n",
      "Searching in area centered at 34.7244264,-120.31821140000001\n",
      "Searching in area centered at 34.7244264,-120.2982114\n",
      "Searching in area centered at 34.7244264,-120.2782114\n",
      "Searching in area centered at 34.7244264,-120.25821140000001\n",
      "Searching in area centered at 34.7244264,-120.2382114\n",
      "Searching in area centered at 34.7444264,-120.31821140000001\n",
      "Searching in area centered at 34.7444264,-120.2982114\n",
      "Fetching next page of results...\n",
      "Fetching next page of results...\n",
      "Searching in area centered at 34.7444264,-120.2782114\n",
      "Fetching next page of results...\n",
      "Fetching next page of results...\n",
      "Searching in area centered at 34.7444264,-120.25821140000001\n",
      "Fetching next page of results...\n",
      "Fetching next page of results...\n",
      "Searching in area centered at 34.7444264,-120.2382114\n",
      "Searching in area centered at 34.764426400000005,-120.31821140000001\n",
      "Searching in area centered at 34.764426400000005,-120.2982114\n",
      "Searching in area centered at 34.764426400000005,-120.2782114\n",
      "Searching in area centered at 34.764426400000005,-120.25821140000001\n",
      "Searching in area centered at 34.764426400000005,-120.2382114\n",
      "Searching in area centered at 34.7844264,-120.31821140000001\n",
      "Searching in area centered at 34.7844264,-120.2982114\n",
      "Searching in area centered at 34.7844264,-120.2782114\n",
      "Searching in area centered at 34.7844264,-120.25821140000001\n",
      "Searching in area centered at 34.7844264,-120.2382114\n",
      "Data saved to los alamos, ca_businesses.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "#SEE WHAT ALL DATA YOU CAN INCLUDE IN THE DATABASE\n",
    "#FIGURE OUT HOW TO BETTER DISTILL THE DATA FOR PCIO. MAYBE JUST TARGET TOP PROSPECTS IN x States?\n",
    "#GET ALL OF THE PARAMETERS POSSIBLE TO FILL IN THE WORKSHEET. AI WILL USE THIS DATA TO CREATE OUTREACH SHOWING THAT WE'VE DONE RESEARCH.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Geocode the town name to get its latitude and longitude\n",
    "def geocode_town(town_name, api_key):\n",
    "    geocode_url = 'https://maps.googleapis.com/maps/api/geocode/json'\n",
    "    params = {\n",
    "        'address': town_name,\n",
    "        'key': api_key\n",
    "    }\n",
    "    response = requests.get(geocode_url, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        if result['results']:\n",
    "            location = result['results'][0]['geometry']['location']\n",
    "            return location['lat'], location['lng']\n",
    "        else:\n",
    "            print(\"No results found for town:\", town_name)\n",
    "            return None, None\n",
    "    else:\n",
    "        print(\"Geocoding failed with status:\", response.status_code)\n",
    "        return None, None\n",
    "\n",
    "# Fetch nearby places from Google Places API\n",
    "def get_nearby_places(api_key, location, radius, pagetoken=None):\n",
    "    endpoint = 'https://maps.googleapis.com/maps/api/place/nearbysearch/json'\n",
    "    params = {\n",
    "        'location': location,\n",
    "        'radius': radius,\n",
    "        'key': api_key\n",
    "    }\n",
    "\n",
    "    if pagetoken:\n",
    "        params['pagetoken'] = pagetoken\n",
    "\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Extract place data including website if available - if there is no website, don't include\n",
    "\n",
    "def extract_place_data(api_key, results):\n",
    "    data = []\n",
    "    for place in results['results']:\n",
    "        place_id = place.get('place_id')\n",
    "        details = get_place_details(api_key, place_id)\n",
    "        website = details.get('result', {}).get('website', None) if details else None  # Set website to None if not available\n",
    "        \n",
    "        # Skip businesses that don't have a website\n",
    "        if website is None:\n",
    "            continue  # Skip to the next place if there's no website\n",
    "        \n",
    "        # Get the types of the place\n",
    "        types = ', '.join(place.get('types', []))  # Join the list of types as a string\n",
    "\n",
    "        data.append({\n",
    "            'Name': place.get('name'),\n",
    "            'Address': place.get('vicinity'),\n",
    "            'Rating': place.get('rating'),\n",
    "            'Business Status': place.get('business_status'),\n",
    "            'Place ID': place_id,\n",
    "            'Website': website,  # Add website to the data\n",
    "            'Type': types  # Add types to the data\n",
    "        })\n",
    "    return data\n",
    "\n",
    "\n",
    "# Save the data to a CSV file\n",
    "def save_to_csv(data, filename):\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "\n",
    "# Get all places in the area and handle pagination\n",
    "def get_all_places(api_key, location, radius):\n",
    "    all_places = []\n",
    "    pagetoken = None\n",
    "    while True:\n",
    "        results = get_nearby_places(api_key, location, radius, pagetoken)\n",
    "        if results and 'results' in results:\n",
    "            place_data = extract_place_data(api_key, results)\n",
    "            all_places.extend(place_data)\n",
    "            \n",
    "            # Check if there's a next page of results\n",
    "            pagetoken = results.get('next_page_token')\n",
    "            if pagetoken:\n",
    "                print(\"Fetching next page of results...\")\n",
    "                time.sleep(2)  # Wait 2 seconds for the next page token to activate\n",
    "            else:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return all_places\n",
    "\n",
    "# Search multiple areas by dividing the town into grids\n",
    "def search_multiple_areas(api_key, base_lat, base_lng, radius, grid_size=4):\n",
    "    all_places = []\n",
    "    \n",
    "    # Step size for dividing the area\n",
    "    lat_step = 0.02  # Adjust based on the size of the town\n",
    "    lng_step = 0.02  # Adjust based on the size of the town\n",
    "    \n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            lat = base_lat + (i - grid_size//2) * lat_step\n",
    "            lng = base_lng + (j - grid_size//2) * lng_step\n",
    "            location = f\"{lat},{lng}\"\n",
    "            print(f\"Searching in area centered at {location}\")\n",
    "            places = get_all_places(api_key, location, radius)\n",
    "            all_places.extend(places)\n",
    "    \n",
    "    return all_places\n",
    "\n",
    "def main():\n",
    "    api_key = google_place_api_key\n",
    "    town_name = input(\"Enter the town name: \")\n",
    "\n",
    "    # Get latitude and longitude from town name\n",
    "    base_lat, base_lng = geocode_town(town_name, api_key)\n",
    "    if base_lat is None or base_lng is None:\n",
    "        print(\"Failed to get coordinates for the town.\")\n",
    "        return\n",
    "\n",
    "    radius = 2000  # Set the radius to 2km for each search area\n",
    "    grid_size = 5  # Divide the town into a 5x5 grid\n",
    "\n",
    "    print(f\"Searching for businesses in {town_name}...\")\n",
    "    \n",
    "    # Search all areas in the town\n",
    "    all_places = search_multiple_areas(api_key, base_lat, base_lng, radius, grid_size)\n",
    "\n",
    "    if all_places:\n",
    "        # Save to CSV\n",
    "        save_to_csv(all_places, f'{town_name}_businesses.csv')\n",
    "    else:\n",
    "        print(\"No businesses found or an error occurred.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74f07c-0a62-4fe2-9318-a659e4e55c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Zoominfo or whatever equivalent, Get company info, see how many people and add to database. Python Scrape, store as variable. use AI with vectorDB about PCIO to go through scrape and see if they're worthwhile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acec3eb-c950-4ba4-b4c3-73262e09a0bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bad4b0-ad40-4251-8c0b-68371e6ffef4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d2a99-8d9f-4278-8d1d-9f7dc15ba49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c78f1e-2013-43bf-98d0-deb73ab78ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apollio.io, lusha, lead411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d755eec6-5fb3-4e2e-807a-d0596362c9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VECTOR DATABASE FOR PYTHON SCRAPE?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92de9f3e-fd16-4b8f-8de9-44679bc51487",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7fb2540-4d8e-45a3-afc2-fead433d7936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764064e-c634-4ae9-8353-6616dc52ac69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b133ef9-98ac-4d72-8702-961f55e33794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b727f09-f937-4d2d-8270-a60439537618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9fc6298-30d9-4b22-9c1e-81298d3ea4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98c88ad-104e-42d3-9d99-cb0c63d08661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae40cce-070c-4649-a7f0-cc457c778e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa4f20-d466-42b9-a3dc-9b302a33d156",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f291c0d-2152-4a9e-adb5-031da8657b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48aa778-9fb3-4b06-b335-b92dc111910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29917e3a-3c4f-45c6-9f01-0cdb576ad23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
