{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "daab331c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/kevincorstorphine/Desktop/Agentic_Start\n",
      "Loading .env file from: /Users/kevincorstorphine/Desktop/Agentic_Start/.env\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "#All of the dependencies are listed in the .toml file. Ensure those are going with Poetry\n",
    "#ensure your .env file is in the right place \n",
    "\n",
    "#make sure you're using poetry shell to get all of the dependencies going in your folder\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "print(os.getcwd())\n",
    "dotenv_path = find_dotenv()\n",
    "print(f\"Loading .env file from: {dotenv_path}\")\n",
    "_ = load_dotenv(dotenv_path)\n",
    "\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "creativeLlmModel = OpenAI(temperature=0.9)\n",
    "chatModel = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b0006a-925a-475d-bf4a-3faf78ae322f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f340c7-4140-4569-8bb9-afa9f88723f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c95b7-591d-499b-b382-07500fffbcae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80da6210-ec6b-48bd-9198-e4db3709e7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"model_background_personality.txt\")\n",
    "scrape_data1 = TextLoader(\"scraped_pages/1example_com_combined.txt\")\n",
    "\n",
    "loaded_data = loader.load()\n",
    "scrape_data1 = scrape_data1.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a56367f8-01e5-49b4-be93-71c09076e4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you need smaller chunks, you can enforce a maximum chunk size\n",
    "#to ensure that the splitter splits. It looks for logical places to split\n",
    "#and the .txt scrapes are jumbled and don't have logical breaks.\n",
    "\n",
    "\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "434a3fbe-353f-4cf6-bb0d-8fecfd16d88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 4565, which is longer than the specified 1000\n",
      "Created a chunk of size 4565, which is longer than the specified 1000\n",
      "Created a chunk of size 1711, which is longer than the specified 1000\n",
      "Created a chunk of size 3141, which is longer than the specified 1000\n",
      "Created a chunk of size 3098, which is longer than the specified 1000\n",
      "Created a chunk of size 1360, which is longer than the specified 1000\n",
      "Created a chunk of size 2155, which is longer than the specified 1000\n",
      "Created a chunk of size 1037, which is longer than the specified 1000\n",
      "Created a chunk of size 1738, which is longer than the specified 1000\n",
      "Created a chunk of size 27868, which is longer than the specified 1000\n",
      "Created a chunk of size 1730, which is longer than the specified 1000\n",
      "Created a chunk of size 29895, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "load = text_splitter.create_documents([loaded_data[0].page_content])\n",
    "scrape1 = text_splitter.create_documents([scrape_data1[0].page_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0302e62-251c-4145-ba11-56e258693f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(load)\n",
    "len(scrape1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63417ba-9f73-4379-99ef-8c4c45cdb3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1fde5872-48d3-4fba-950d-991bb6ecb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Loaded_data is the personality I gave the model in the model_background_personality.txt file. I told it to be a pirate. In the live version\n",
    "#change this to the background about API3 and the product. \n",
    "\n",
    "#it is a pirate doing cold outreach selling bananas. \n",
    "\n",
    "\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a {kind_of_entity}.\"),\n",
    "        (\"human\", \"Hello, can you please answer a question?\"),\n",
    "        (\"ai\", \"Sure!\"),\n",
    "        (\"human\", \"{user_input}{scrape_detail}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    kind_of_entity=str(load),\n",
    "   # topic=\"pirating\",\n",
    "    user_input= \"Please write an outbound cold email about the problems they may be facing without a reliable helpdesk IT support service\",\n",
    "    scrape_detail=str(scrape1),\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9eaad99-9768-4cc1-93b6-d080f02732f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Unlock New Potential for Your Decentralized Applications\n",
      "\n",
      "Hi [Recipient's Name],\n",
      "\n",
      "I hope this message finds you well. As a developer in the rapidly evolving Web3 space, you might be facing challenges with data reliability and security when integrating APIs into your decentralized applications. \n",
      "\n",
      "Many teams struggle with the risks associated with third-party oracle services, which can expose your applications to unnecessary vulnerabilities and inefficiencies. The reliance on middlemen not only complicates data integrity but can also lead to significant losses due to oracle extractable value (OEV) issues.\n",
      "\n",
      "At API3, we understand these challenges and have developed solutions designed to address them directly. Our Airnode technology offers a seamless way to connect your APIs directly to any blockchain application without the need for intermediary operators. This not only enhances security and transparency but also maximizes the accuracy of the data your dApps rely on.\n",
      "\n",
      "**Here’s how we can help:**\n",
      "\n",
      "1. **Direct Data Sources:** Our decentralized APIs (dAPIs) pull data straight from high-quality providers, ensuring that your applications are powered by the most reliable and up-to-date information.\n",
      "\n",
      "2. **OEV Network:** With our OEV Network, you can recapture significant value that would typically be lost in traditional lending protocols. This allows your projects to operate more efficiently and competitively.\n",
      "\n",
      "3. **Multi-Chain Compatibility:** Our solutions are designed to work across various EVM-compatible blockchains, giving you the flexibility to build and scale without constraints.\n",
      "\n",
      "If you’re interested in exploring how API3 can help streamline your development process and enhance the security of your applications, I’d love to schedule a time to discuss this further. \n",
      "\n",
      "Looking forward to hearing from you!\n",
      "\n",
      "Best regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "API3  \n",
      "[Your Contact Information]  \n"
     ]
    }
   ],
   "source": [
    "print(response.content) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f7a773-9186-40ed-9317-00d19580265a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "\n",
    "#examples are a way to train the model to react exactly how you want it to.\n",
    "#in the class example, this was is way to get it to speak Spanish\n",
    "#FewshotChatprompttemplate is just chatPromptTemplate with examples\n",
    "#Use this further modeling to refine the pitch, say waht works, what doesn't, etc.\n",
    "\n",
    "#train AI on how you want an outbound email to look. These are just two examples of how to train it:\n",
    "examples = [\n",
    "    {\"input\": \"hi!\", \"output\": \"¡hola!\"},\n",
    "    {\"input\": \"bye!\", \"output\": \"¡adiós!\"},\n",
    "]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \" you are only targeting Spanish speaking communities and are translating to spanish\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "#a chain defines a sequence of order in which to run\n",
    "\n",
    "\n",
    "chain = final_prompt | chatModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb550660-4b38-4f78-a3b4-3a2d44d75dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Claro! Imaginemos que estoy vendiendo un purificador de aire.\n",
      "\n",
      "---\n",
      "\n",
      "¡Hola! ¿Te has dado cuenta de cuánto tiempo pasamos en interiores? La calidad del aire que respiramos en casa o en la oficina puede afectar nuestra salud y bienestar. Te presento nuestro purificador de aire de última generación.\n",
      "\n",
      "Este purificador no solo elimina el 99.9% de los alérgenos y contaminantes del aire, como el polvo, el polen y el moho, sino que también cuenta con un sistema de filtración HEPA que garantiza un ambiente más saludable para ti y tu familia. \n",
      "\n",
      "Además, su diseño elegante se adapta a cualquier espacio, y su funcionamiento es tan silencioso que apenas notarás que está trabajando. También cuenta con un temporizador y modos de funcionamiento que puedes ajustar según tus necesidades.\n",
      "\n",
      "Imagina respirar aire fresco y limpio todos los días. ¡Haz la inversión en tu salud y bienestar hoy! Con cada compra, te ofrecemos un 20% de descuento durante este mes. No dejes pasar esta oportunidad. \n",
      "\n",
      "¿Qué dices? ¿Te gustaría saber más sobre cómo mejorar la calidad del aire en tu hogar?\n",
      "\n",
      "--- \n",
      "\n",
      "¿Te gustaría que ajuste el enfoque o el producto?\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"input\": \"please do a sales pitch to someone based on the product you sell\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "475c525b-f1b9-4954-9034-728b7c67de9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ADDITIONAL JSON PARSING STUFF< CHECK OUT THE PYDANTIC LIBRARY\n",
    "\n",
    "\n",
    "# from langchain_core.prompts import PromptTemplate\n",
    "# from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "# json_prompt = PromptTemplate.from_template(\n",
    "#     \"Return a JSON object with an `answer` key that answers the following question: {question}\"\n",
    "# )\n",
    "\n",
    "# json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "# json_chain = json_prompt | llmModel | json_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2486f803-35dd-4fa8-b76a-c770b5fc16a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9b8a95b-5b40-4617-9367-29024f643ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_chain.invoke({\"question\": \"What is the biggest country?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27939aa-c158-4b7f-bcbb-9d93b21df195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7dadc2f4-08ec-4737-8f17-74fc1314fe25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7e1b5d2-2123-4f04-843c-b7fcc0af4b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f65f6378-03b8-4041-a1bd-9c94b2e9e8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2287bca8-9405-4595-b3aa-9d1bf0a7c4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e12a893a-81c8-4b17-932d-83a0ff629b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ed06f9-d74b-4e7a-8a14-437d5cb9e413",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
